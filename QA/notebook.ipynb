{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Tesseract OCR\n",
    "https://tesseract-ocr.github.io/tessdoc/Installation.html\n",
    "\n",
    "`sudo apt install tesseract-ocr` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      ">| ChatGPT-like bot zt\n",
      "\n",
      "Enter your message:\n",
      "\n",
      " \n",
      "\n",
      "Hello!\n",
      "\n",
      "‘@ ChatGPT:\n",
      "\n",
      "Hi! How may | assist you today?\n",
      "\n",
      "Made with Streamlit ra\n",
      "\f\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Set the path to the image file\n",
    "img_path = '../img/chatGPT.png'\n",
    "\n",
    "# Open the image using PIL\n",
    "with Image.open(img_path) as img:\n",
    "    # Use Pytesseract to read text from the image\n",
    "    text = pytesseract.image_to_string(img)\n",
    "\n",
    "# Print the extracted text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "pages = os.listdir('../book/')\n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IMG_20230409_194818.jpg',\n",
       " 'IMG_20230409_194826.jpg',\n",
       " 'IMG_20230409_194833.jpg',\n",
       " 'IMG_20230409_194842.jpg',\n",
       " 'IMG_20230409_194857.jpg',\n",
       " 'IMG_20230409_194905.jpg',\n",
       " 'IMG_20230409_194914.jpg',\n",
       " 'IMG_20230409_194922.jpg',\n",
       " 'IMG_20230409_194929.jpg',\n",
       " 'IMG_20230409_194935.jpg',\n",
       " 'IMG_20230409_194942.jpg',\n",
       " 'IMG_20230409_194948.jpg',\n",
       " 'IMG_20230409_194955.jpg',\n",
       " 'IMG_20230409_195004.jpg',\n",
       " 'IMG_20230409_195008.jpg',\n",
       " 'IMG_20230409_195012.jpg']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages.sort()\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "  \n",
      "  \n",
      "  \n",
      "   \n",
      "  \n",
      " \n",
      "  \n",
      " \n",
      "   \n",
      "  \n",
      "  \n",
      "   \n",
      "  \n",
      "\n",
      "attract custom\n",
      "being, distribution\n",
      "\n",
      "Customer-Oriented Distr’\n",
      "\n",
      "The world of high-tech sales, marketin\n",
      "\n",
      "been changing dramatically over the p\n",
      "to the increasing impact of the World W:\n",
      "\n",
      "not been changing, On the other hand, «\n",
      "distribution channels are targeting. Ess\n",
      "\n",
      "into five classes, each of which is associ\n",
      "\n",
      "approae hy:\n",
      "\n",
      "|, Enterprise executives making big-ticket |\n",
      "focused on complex systems to be ad ,\n",
      "their companies,\n",
      "\n",
      "2, End users making relatively low-cost pu\n",
      "\n",
      "focused on personal or workgroup tech\n",
      "\n",
      "opted locally and individually,\n",
      "\n",
      "Department heads making medium-cost f\n",
      "\n",
      "—\n",
      "\n",
      "for Use -Case tf\n",
      "W Use -Case specific solutions that will\n",
      "their own organization,\n",
      "4, Lingineers maki )\n",
      "Wii making design decisions for pt }\n",
      "(oO be |\n",
      "sold to their company’s customers,\n",
      "\f\n"
     ]
    }
   ],
   "source": [
    "img_path = '../book/'+pages[1]\n",
    "with Image.open(img_path) as img:\n",
    "    # Use Pytesseract to read text from the image\n",
    "    text = pytesseract.image_to_string(img)\n",
    "\n",
    "# Print the extracted text\n",
    "print(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF reader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://archive.org/details/crossingthechasm_202002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /home/codespace/.local/lib/python3.10/site-packages (0.0.136)\n",
      "Requirement already satisfied: openai in /home/codespace/.local/lib/python3.10/site-packages (0.27.4)\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-0.3.21-py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tiktoken in /home/codespace/.local/lib/python3.10/site-packages (0.3.3)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-3.7.1-py3-none-any.whl (248 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.1/248.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (1.24.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (1.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (2.28.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (1.4.47)\n",
      "Requirement already satisfied: tqdm in /home/codespace/.local/lib/python3.10/site-packages (from openai) (4.65.0)\n",
      "Collecting hnswlib>=0.7\n",
      "  Downloading hnswlib-0.7.0.tar.gz (33 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sentence-transformers>=2.2.2\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting fastapi>=0.85.1\n",
      "  Downloading fastapi-0.95.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting duckdb>=0.7.1\n",
      "  Downloading duckdb-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting posthog>=2.4.0\n",
      "  Downloading posthog-2.4.2-py2.py3-none-any.whl (36 kB)\n",
      "Collecting clickhouse-connect>=0.5.7\n",
      "  Downloading clickhouse_connect-0.5.20-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (921 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m921.9/921.9 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting uvicorn[standard]>=0.18.3\n",
      "  Downloading uvicorn-0.21.1-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.3 in /home/codespace/.local/lib/python3.10/site-packages (from chromadb) (1.5.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/codespace/.local/lib/python3.10/site-packages (from tiktoken) (2023.3.23)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Collecting lz4\n",
      "  Downloading lz4-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz in /home/codespace/.local/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2023.3)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.12.7)\n",
      "Collecting zstandard\n",
      "  Downloading zstandard-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3>=1.26 in /home/codespace/.local/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.15)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /home/codespace/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /home/codespace/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Collecting starlette<0.27.0,>=0.26.1\n",
      "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/codespace/.local/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /home/codespace/.local/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb) (1.13.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.1-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb) (1.2.2)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb) (1.10.1)\n",
      "Requirement already satisfied: nltk in /home/codespace/.local/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb) (3.8.1)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
      "Requirement already satisfied: h11>=0.8 in /home/codespace/.local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: click>=7.0 in /home/codespace/.local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.3)\n",
      "Collecting httptools>=0.5.0\n",
      "  Downloading httptools-0.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (414 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m414.1/414.1 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-dotenv>=0.13\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0\n",
      "  Downloading uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting websockets>=10.4\n",
      "  Downloading websockets-11.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting watchfiles>=0.13\n",
      "  Downloading watchfiles-0.19.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.9 in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (23.0)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.11.0-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/codespace/.local/lib/python3.10/site-packages (from starlette<0.27.0,>=0.26.1->fastapi>=0.85.1->chromadb) (3.6.2)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (67.6.0)\n",
      "Requirement already satisfied: wheel in /home/codespace/.local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (0.38.4)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mypy-extensions>=0.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.10/site-packages (from nltk->sentence-transformers>=2.2.2->chromadb) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from torchvision->sentence-transformers>=2.2.2->chromadb) (9.5.0)\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.0.0\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (3.1.2)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting cmake\n",
      "  Downloading cmake-3.26.1-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting lit\n",
      "  Downloading lit-16.0.0.tar.gz (144 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.27.0,>=0.26.1->fastapi>=0.85.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (2.1.2)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: hnswlib, sentence-transformers, lit\n",
      "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hnswlib: filename=hnswlib-0.7.0-cp310-cp310-linux_x86_64.whl size=2120246 sha256=3b928989708b394656c86b731d69ee34efef201c59dc5db59f6f28b21b00e3b3\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/8a/ae/ec/235a682e0041fbaeee389843670581ec6c66872db856dfa9a4\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125925 sha256=e8b793310f688743554e9b003043329499fda8de856c7b4491e8fce111a186e7\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
      "  Building wheel for lit (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-16.0.0-py3-none-any.whl size=93582 sha256=c31eeb49f9dc098fc774bf96e1d28329a674ca1058022f0e71ed51ca8c71a8dc\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/a3/f5/8f/b11227e816563ac08fce423c6e617f05f5fe1a18d9bcfb2375\n",
      "Successfully built hnswlib sentence-transformers lit\n",
      "Installing collected packages: tokenizers, sentencepiece, mpmath, lit, duckdb, cmake, zstandard, websockets, uvloop, uvicorn, sympy, python-dotenv, pypdf, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-cupti-cu11, networkx, lz4, httptools, hnswlib, filelock, watchfiles, starlette, posthog, nvidia-cusolver-cu11, huggingface-hub, clickhouse-connect, transformers, fastapi, triton, torch, torchvision, sentence-transformers, chromadb\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.1\n",
      "    Uninstalling torch-1.13.1:\n",
      "      Successfully uninstalled torch-1.13.1\n",
      "Successfully installed chromadb-0.3.21 clickhouse-connect-0.5.20 cmake-3.26.1 duckdb-0.7.1 fastapi-0.95.0 filelock-3.11.0 hnswlib-0.7.0 httptools-0.5.0 huggingface-hub-0.13.4 lit-16.0.0 lz4-4.3.2 mpmath-1.3.0 networkx-3.1 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 posthog-2.4.2 pypdf-3.7.1 python-dotenv-1.0.0 sentence-transformers-2.2.2 sentencepiece-0.1.97 starlette-0.26.1 sympy-1.11.1 tokenizers-0.13.3 torch-2.0.0 torchvision-0.15.1 transformers-4.27.4 triton-2.0.0 uvicorn-0.21.1 uvloop-0.17.0 watchfiles-0.19.0 websockets-11.0.1 zstandard-0.20.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain openai chromadb tiktoken pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load document\n",
    "loader = PyPDFLoader(\"Crossing the Chasm.pdf\")\n",
    "documents = loader.load()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load document\n",
    "loader = PyPDFLoader(\"book/Crossing the Chasm-202-217.pdf\")\n",
    "documents = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The given portion of the document does not provide a clear definition of Vendor-Oriented Pricing. However, it mentions that \"vendor-oriented pricing represents the least sound basis for pricing decisions during the chasm period.\"'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "chat = ChatOpenAI(model_name='gpt-3.5-turbo')\n",
    "\n",
    "chain = load_qa_chain(llm=chat, chain_type=\"map_reduce\")\n",
    "query = \"what is Vendor-Oriented Pricing?\"\n",
    "chain.run(input_documents=documents, question=query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "# split the documents into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "# select which embeddings we want to use\n",
    "embeddings = OpenAIEmbeddings()\n",
    "# create the vectorestore to use as the index\n",
    "db = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expose this index in a retriever interface\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})\n",
    "# create a chain to answer questions \n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=chat, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n",
    "query = \"what is Vendor-Oriented Pricing?\"\n",
    "result = qa({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'what is Vendor-Oriented Pricing?',\n",
       " 'result': 'Vendor-oriented pricing is a pricing strategy that is based on internal factors such as the cost of goods, cost of sales, cost of overhead, cost of capital, promised rate of risk-adjusted return, and any number of other factors critical to managing an enterprise profitably on an ongoing basis. Its impact is on the number of transactions required to create a given amount of annual revenue. It sets the distribution channel decision by establishing a price-point ballpark that puts the product in the direct sales, web self-service, or sales 2.0 camp. The pricing strategy is not the most sound basis for pricing decisions during the chasm period, as it requires being almost entirely externally focused- both on the new demands of the mainstream customer and the new relationship you are trying to build with a mainstream channel.',\n",
       " 'source_documents': [Document(page_content='208 Crossing the Chasm\\nVendor -Oriented Pricing\\nVendor-oriented pricing is a function of internal issues, begin\\xad\\nning with cost of goods , and extending to cost of sales, cost of \\noverhead, cost of capital, promised rate of risk-adjusted return, \\nand any number of other factors. These factors are critical to \\nbeing able to manage an enterprise profitably on an ongoi ng \\nbasis. None of these, however, has any immediate meaning in \\nthe marketplace. They take on meaning only as they impact \\nother market-visible issues.\\nFor example, vendor-oriented pricing typically sets the dis\\xad\\ntribution channel decision by establishing a price-point ballpark \\nthat puts the produc t in the direct sales, Web self-service, or \\nSales 2.0 camp. Moreover, once the produc t is in the market, \\nvendor-oriented factors can make a big impact if, for example, \\nthey allow for a low-cost pricing advantage in a late mainstream \\nmarket, or if they allow for operating margins that can fund \\nnew R&D for the next early market.\\nThe biggest impact of vendor-oriented pricing is on the \\nnumber of transactions required to create a given amount of \\nannua l revenue. Suppos e the target were $10 million, which if \\nit came from a single beachhead segment is a reasonable revenue \\nstream to sugge st you have successfully crossed the chasm. In an \\nOEM model fulfilled through two-tier distribution, that could \\nbe the result of just one or two big design wins. In a direct sales \\nmodel, it is probably more like twenty to forty transactions, \\nwith half of it coming from perhaps the top five. In a Sales \\n2.0 model, you would probably multiply that by ten—s ay, 200 \\nto 400 transactions. And in a VAR-enabled model going after \\nsmall businesses, multiply by another ten, and for a consumer \\nhigh-volume model, still another ten—s ay, 20,000—40,000 \\ntransactions averaging around $25/ month.', metadata={'source': 'Crossing the Chasm.pdf', 'page': 212}),\n",
       "  Document(page_content='Launch the Invasion 209\\nAs you can see, each of these price points will call into being \\na different management perspective on the sales funnel, top to \\nbottom, from suspect to prospect to qualified lead all the way to \\nclosed customer. The higher the volume, the more transactional \\nthe process, and the more you depend on filling the top of the \\nfunnel. The higher the price, the more relationship-oriented the \\nprocess, the more you focus on the bottom of the funnel. And, \\nyes, with Sales 2.0 you do tend to focus most on the middle of \\nthe funnel, where process effectiveness and efficiency have their \\nbiggest impacts.\\nThat all said, vendor-oriented pricing represents the least \\nsound basis for pricing decisions during the chasm period. This \\nis a time when you must be almost entirely externally focused— \\nboth on the new demands of the mainstream customer and the \\nnew relationship you are trying to build with a mainstream \\nchannel. Indeed, becausb of the primary importance of secur\\xad\\ning ongoing means of access to the mainstream, this latter issue \\nshould be the number-one factor for pricing decisions during \\nthis period.\\nDistribution-Oriented Pricing\\nFrom a distribution perspective, there are two pricing issues that \\nhave significant impact on channel motivation:\\n• Is it priced to sell?\\n• Is it worthwhile to sell?\\nBeing priced to sell means that price does not become a \\nmajor issue during the sales cycle. Companies crossing the \\nchasm, coming from success in the early market with visionary \\ncustomers, typically have their products priced too high. Price', metadata={'source': 'Crossing the Chasm.pdf', 'page': 213}),\n",
       "  Document(page_content='206 Crossing the Chasm\\ntherefore, that the channel/strategy fit be a good one, and there\\nis no shame in switching channels if your first choice is not\\nbearing proper fruit.\\nDistribution-Oriented Pricing\\nPricing decisions are among the hardest for management groups\\nto reach consensus on. The problem is that there are so many\\nperspectives competing for the controlling influence. In this sec\\xad\\ntion we are going to sort out some of those perspectives and set\\nout some rational guidelines for pricing during the chasm period.\\nCustomer-Oriented Pricing\\nThe first perspective to set on pricing is the customers’, and, as\\nwe noted in the section on discovering the chasm, that varies\\ndramatically with their psychographics. Visionaries—the cus\\xad\\ntomers dominating the early market’s development—are rela\\xad\\ntively price-insensitive. Seeking a strategic leap forward, with\\nan order-of-magnitude return on investment, they are con\\xad\\nvinced that any immediate costs are insignificant when com\\xad\\npared with the end result. Indeed, they want to make sure there\\nis, if anything, extra money in the price, because they know they\\nare going to need special service, and they want their vendors to\\nhave the funding to provide it. There is even a kind of prestige\\nin buying the high-priced alternative. All this is pure value-based\\npricing. Because of the high value placed on the end result, the\\nproduct price has a high umbrella under which it can unfold.\\nAt the other end of the market are the conservatives. They\\nwant low pricing. They have waited a long time before buying', metadata={'source': 'Crossing the Chasm.pdf', 'page': 210})]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vendor-oriented pricing is a pricing strategy that is based on internal factors such as the cost of goods, cost of sales, cost of overhead, cost of capital, promised rate of risk-adjusted return, and any number of other factors critical to managing an enterprise profitably on an ongoing basis. Its impact is on the number of transactions required to create a given amount of annual revenue. It sets the distribution channel decision by establishing a price-point ballpark that puts the product in the direct sales, web self-service, or sales 2.0 camp. The pricing strategy is not the most sound basis for pricing decisions during the chasm period, as it requires being almost entirely externally focused- both on the new demands of the mainstream customer and the new relationship you are trying to build with a mainstream channel.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['result']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VectorstoreIndexCreator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapper for the logic above\n",
    "\n",
    "Source:\n",
    "\n",
    "https://python.langchain.com/en/latest/modules/chains/getting_started.html\n",
    "https://github.com/hwchase17/langchain/blob/master/langchain/indexes/vectorstore.py#L21-L74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    # split the documents into chunks\n",
    "    text_splitter=CharacterTextSplitter(chunk_size=1000, chunk_overlap=0),\n",
    "    # select which embeddings we want to use\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    # use Chroma as the vectorestore to index and search embeddings\n",
    "    vectorstore_cls=Chroma\n",
    ").from_loaders([loader])\n",
    "index.query(llm=chat, question=query, chain_type=\"stuff\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversationalRetrievalChain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conversation memory + RetrievalQAChain\n",
    "\n",
    "Allow for passing in chat history which can be used for follow up questions.\n",
    "\n",
    "Source: https://python.langchain.com/en/latest/modules/chains/index_examples/chat_vector_db.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the documents into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "# select which embeddings we want to use\n",
    "embeddings = OpenAIEmbeddings()\n",
    "# create the vectorestore to use as the index\n",
    "db = Chroma.from_documents(texts, embeddings)\n",
    "# expose this index in a retriever interface\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":2})\n",
    "# create a chain to answer questions \n",
    "qa = ConversationalRetrievalChain.from_llm(chat, retriever)\n",
    "chat_history = []\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [(query, result[\"answer\"])]\n",
    "query = \"How does it differ from Distribution-Oriented Pricing?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['answer']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
