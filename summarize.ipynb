{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize\n",
    "\n",
    "Summarize Teams conversations with ChatGPT with VTT files\n",
    "\n",
    "https://webvtt-py.readthedocs.io/en/latest/usage.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import webvtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YannMike_2023-03-08.vtt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('vtt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<v Yann>Why is my French accent?</v>\n",
      "<v Yann>I I want to stop doing this experiment where.</v>\n",
      "<v Yann>We some a conversation we record it's generating a VTT file.</v>\n",
      "<v Yann>And I have a a a parcel. I developed a small app in Python that can retrieve the VTT like process it OK.</v>\n",
      "<v Yann>And then.</v>\n",
      "<v Yann>I want to feed it through the to GPT stuff API and the API is amazing. I don't know if you've played around with it already.</v>\n",
      "<v Mike>No, I need to though the. Yeah, the problem is I can't find too many things. I promised people so every day.</v>\n"
     ]
    }
   ],
   "source": [
    "file = 'YannMike_2023-03-08.vtt'\n",
    "chat = webvtt.read('vtt/'+file)\n",
    "for caption in chat[0:10]:\n",
    "    # print(f'From {caption.start} to {caption.end}')\n",
    "    print(caption.raw_text)\n",
    "    # print(caption.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = 'YannMike_2023-03-08.txt'\n",
    "# for caption in chat:\n",
    "#     with open('txt/'+txt,mode='a') as f:\n",
    "#         f.write(caption.text+'\\n')\n",
    "\n",
    "str = []\n",
    "for caption in chat:\n",
    "    str.append(caption.text)\n",
    "sep = '\\n'\n",
    "convo = sep.join(str)\n",
    "with open('txt/'+txt,mode='w') as f:\n",
    "    f.write(convo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many Tokens?\n",
    "- https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them\n",
    "- https://github.com/openai/tiktoken\n",
    "- https://platform.openai.com/tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first order\n",
    "tokens = convo.split() # split the string into tokens\n",
    "num_tokens = len(tokens)\n",
    "num_tokens\n",
    "\n",
    "# # pip install nltk\n",
    "# import nltk\n",
    "# len(nltk.word_tokenize(convo))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomli\n",
    "import openai\n",
    "with open('.streamlit/secrets.toml','rb') as f:\n",
    "    toml_dict = tomli.load(f)\n",
    "openai.api_key = toml_dict['OPEN_AI_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The conversation is about someone discussing their experiment of using a Python app to retrieve VTT files and using the GPT API to process them. They talk about difficulties finding information on the topic and their overall interest in the API.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = 'summarize the following conversation'\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "      messages=[\n",
    "        {'role': 'system','content': context},\n",
    "        {'role': 'user', 'content': convo}\n",
    "            ]\n",
    ")\n",
    "completion.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
